<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Attention机制</title>
    <link href="/2020/08/30/Attention%E6%9C%BA%E5%88%B6/"/>
    <url>/2020/08/30/Attention%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="两种注意力机制"><a href="#两种注意力机制" class="headerlink" title="两种注意力机制"></a>两种注意力机制</h1><p>​        在神经学中的注意力机制通常有两种，一种是聚焦式注意力机制（Fcous Attention），这种注意力机制指的是主动有意识的将聚焦于某一对象的注意力。另一种是自下而上的无意识的注意力机制，称为基于显著性的注意力机制（Saliency-Based Attention），这种注意力机制是无意识的，当有外界刺激时，才会去注意。一个例子就是<strong>鸡尾酒会效应</strong>，当一个人在吵闹的鸡尾酒会上和朋友聊天时，即使周围很吵闹干扰很多，他还是可以听到朋友说话的内容，这就是聚焦式注意力机制；但是当有人突然叫他的名字，他也能反应过来，这种就是无意识的基于显著性的注意力。</p><p>​        我们希望神经网络能够模仿人的注意力的机制，在下面的介绍中，默认指的是聚焦式的注意力机制，我们希望神经网络能够关注到我们给他指定的信息。</p><h1 id="注意力机制的基本原理"><a href="#注意力机制的基本原理" class="headerlink" title="注意力机制的基本原理"></a>注意力机制的基本原理</h1><h2 id="Soft-Attention模型"><a href="#Soft-Attention模型" class="headerlink" title="Soft Attention模型"></a>Soft Attention模型</h2><p> <img src="/images/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-1.png" alt="preview"></p><p>这里的一个场景是：翻译句子“ Tom chase Jerry ”成“汤姆追逐杰瑞”，由上图可以看到我们希望的是当我们翻译X_1=tom时，那么需要将Y_1注意到X_1这里，当翻译X_2=chase，Y_2=追逐就需要注意到X_2，如果Encoder仅仅输出一个数值，那么对于Decoder来说，Tom chase Jerry是相同分量的东西，这样效果可能就会不好。下面是目标句子中每个单词生成的过程：<br>$$<br>y_1 = f(C_1)<br>$$<br>$$<br>y_2 = f(C_2,y_1) \<br>$$<br>$$<br>y_3 = f(C_3, y_1, y_2)<br>$$<br>其中f是非线性函数，可以用RNN来代替。这里使用注意力概率分布来指代当前注意力集中的大小。对于英汉翻译来说，下面的公式表示了注意力概率分布。<br>$$<br>C_{汤姆}=g(0.6\times f1(“Tom”), 0.2\times f1(“Chase”), 0.2\times f1(“Jerry”))  \<br>$$<br>$$<br>C_{追逐}=g(0.2\times f1(“Tom”), 0.7\times f1(“Chase”), 0.1\times f1(“Jerry”))  \<br>$$<br>$$<br>C_{杰瑞}=g(0.3\times f1(“Tom”), 0.2\times f1(“Chase”), 0.5\times f1(“Jerry”))<br>$$<br>其中f1表示Encoder对英文单词做的某些变换，可以是RNN模型中，隐藏状态h。g实际上做的运算就是加权求和，但是具体到这个场景中就是Encoder根据单词的中间表示合成整个句子中间语义表示的变换函数，公式如下：<br>$$<br>C_i = \sum^{Lx}_{j=1}h_ja_{ij}<br>$$<br>Lx表示输入句子Source的长度，a_ij表示在Target输出第i个单词时，Source输入句子中第j个单词的注意力分配系数，而h_j表示Source输入句子中第j个单词的语义编码。假设下标i就是上面例子所说的“Chase”，那么Lx就是3，h1=f(“Tom”),h2=f(“Chase”),h3=f(“Jerry”)分别是输入句子中每个单词的语义编码，对应的注意力权值分别是0.6，0.2，0.2。下图是C_i的运算过程。</p><p><img src="/images/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-2.jpg"><br>现在稍作总结，我们需要根据不同的目标变换我们的注意力，也就是C_i，而C是由Source中每个单词的语义编码乘上对应的权值，并将所有单词相加得来的，语义编码可以由RNN等模型来做，现在问题是如何求得每个单词的注意力权值，这就引入了注意力分布的概念，利用注意力分布来求出每个单词的注意力权值。</p><h2 id="注意力分布"><a href="#注意力分布" class="headerlink" title="注意力分布"></a>注意力分布</h2><p>这里不限定场景，就是从N个输入向量[x_1, …, x_N]中选择出和某个特定任务相关的信息，需要引入一个和任务相关的表示，称为查询向量（Query Vector），通过一个打分函数来计算每一个输入向量和查询向量之间的相关性。这里的查询向量类似于上面的我们从Target中取出的“Tom”。注意力变量z表示在Source中被选择用来计算注意力权值的索引，z=i表示选择了第i个输入向量。首先计算在给定X和q的情况下，选择第i个输入向量的概率a_i.<br>$$a_i = p(z=i|X,q) $$<br>$$= softmax(s(x_i, q)) $$<br>$$= \frac{exp(s(x_i, q))}{\sum^{N}_{j=1}exp(s(x_j, q))}$$<br>其中a_i称为注意力分布（Attention Distribution），s（x_i， q）为注意力打分函数。也就是说我们拿Target中的汤姆来一一和输入向量中的“Tom”，“Chase”，“Jerry”来做打分，最后计算每个单词与汤姆的概率，概率大的说明权重就大。这里打分函数有以下4种。<br>$$<br>加性模型\qquad s(x_i, q)=v^Ttanh(Wx_i+Uq)<br>$$<br>$$<br>点积模型\qquad s(x_i, q)=x_i^Tq\qquad\qquad\qquad\quad\<br>$$<br>$$<br>缩放点积模型\qquad s(x_i, q)=\frac{x_i^Tq}{\sqrt{d}}\qquad\qquad\quad\<br>$$<br>$$<br>双线性模型\qquad s(x_i, q) = x_i^TWq\qquad\qquad\quad\<br>$$<br>其中W，U，v为可学习的参数，d为输入向量的维度。点积模型更好的利用矩阵乘积，计算效率更高。但当输入向量的维度d比较高时，点积模型的值通常有比较大的方差，从而导致softmax函数的梯度较小，缩放点积可以较好地处理这个问题。</p><p><strong>加权平均</strong>注意力分布a_i可以解释为在给任务相关的查询q时，第i个输入向量受关注的程度。我们采用一个中“软性”的信息机制对输入信息进行汇总。<br>$$<br>att(X, q) = \sum^{N}_{i=1}a_ix_i<br>$$<br>上述公式就是软性注意力机制（Soft Attention Mechanism），下面给出软性注意力机制的示例。</p><p><img src="/images/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-3.png"></p><h2 id="注意力机制的变体"><a href="#注意力机制的变体" class="headerlink" title="注意力机制的变体"></a>注意力机制的变体</h2><p>键值对注意力</p><p>参考：<br><a href="https://blog.csdn.net/hpulfc/article/details/80448570">https://blog.csdn.net/hpulfc/article/details/80448570</a><br><a href="https://blog.csdn.net/hpulfc/article/details/80449561">https://blog.csdn.net/hpulfc/article/details/80449561</a><br><a href="https://blog.csdn.net/jesseyule/article/details/101633159">https://blog.csdn.net/jesseyule/article/details/101633159</a><br>《神经网络与深度学习》</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>Attention</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch官方文档之torch.Tensor</title>
    <link href="/2020/05/16/PyTorch%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E4%B9%8Btorch-Tensor/"/>
    <url>/2020/05/16/PyTorch%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E4%B9%8Btorch-Tensor/</url>
    
    <content type="html"><![CDATA[<p>torch分别定义了CPU中存储和GPU中存储的两种类型.</p><a id="more"></a><table><thead><tr><th>Data type</th><th>dtype</th><th>CPU tensor</th><th>GPU tensor</th></tr></thead><tbody><tr><td>32-bit floating point</td><td>torch.float32 or torch.float</td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>64-bit floating point</td><td>torch.float64 or torch.double</td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr><tr><td>16-bit floating point</td><td>torch.float16 or torch.half</td><td>torch.HalfTensor</td><td>torch.cuda.HalfTensor</td></tr><tr><td>8-bit integer (unsigned)</td><td>torch.uint8</td><td>torch.ByteTensor</td><td>torch.cuda.ByteTensor</td></tr><tr><td>8-bit integer (signed)</td><td>torch.int8</td><td>torch.CharTensor</td><td>torch.cuda.CharTensor</td></tr><tr><td>16-bit integer (signed)</td><td>torch.int16 or torch.short</td><td>torch.ShortTensor</td><td>torch.cuda.ShortTensor</td></tr><tr><td>32-bit integer (signed)</td><td>torch.int32 or torch.int</td><td>torch.IntTensor</td><td>torch.cuda.IntTensor</td></tr><tr><td>64-bit integer (signed)</td><td>torch.int64 or torch.long</td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr><tr><td>Boolean</td><td>torch.bool</td><td>torch.BoolTensor</td><td>torch.cuda.BoolTensor</td></tr><tr><td>torch.Tensor()等于就是torch.FloatTensor()</td><td></td><td></td><td></td></tr></tbody></table><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</code></pre><pre><code class="hljs python">a = torch.Tensor(<span class="hljs-number">1</span>) <span class="hljs-comment"># torch.Tensor()就是默认数据类型为torch.FloatTensor()的张量</span>b = torch.FloatTensor(<span class="hljs-number">1</span>)a,b <span class="hljs-comment"># torch.Tensor()创建一个默认类型为torch.FloatTensor()的张量,torch.FloatTensor()是CPU中类型</span></code></pre><pre><code>(tensor([1.4013e-45]), tensor([1.4013e-45]))</code></pre><p>使用Python中的list创建tensor张量,或者使用np.array()也可以</p><pre><code class="hljs python">a = torch.tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">-1.</span>], [<span class="hljs-number">1.</span>, <span class="hljs-number">-1.</span>]]) <span class="hljs-comment"># 注意,这里创建的是内容为1.和-1.的tensor,不是维度,</span>b = torch.tensor(((<span class="hljs-number">1.</span>, <span class="hljs-number">-1.</span>), (<span class="hljs-number">1.</span>, <span class="hljs-number">-1.</span>))) <span class="hljs-comment"># 并且,这里用[]或()都一样</span>a, b</code></pre><pre><code>(tensor([[ 1., -1.],         [ 1., -1.]]), tensor([[ 1., -1.],         [ 1., -1.]]))</code></pre><pre><code class="hljs python">torch.tensor(np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]]))</code></pre><pre><code>tensor([[1, 2, 3],        [4, 5, 6]], dtype=torch.int32)</code></pre><p>PS: 使用requires_grad_()或者detach()允许更改requires_grad的标志<br>使用torch.dtype指定类型,使用torch.device指定存储的位置</p><pre><code class="hljs python">torch.zeros([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>], dtype=torch.int32)</code></pre><pre><code>tensor([[0, 0, 0, 0],        [0, 0, 0, 0]], dtype=torch.int32)</code></pre><pre><code class="hljs python">cuda = torch.device(<span class="hljs-string">&#x27;cuda:0&#x27;</span>)torch.ones([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>], dtype=torch.float64, device=cuda)</code></pre><pre><code>tensor([[1., 1., 1., 1.],        [1., 1., 1., 1.]], device=&#39;cuda:0&#39;, dtype=torch.float64)</code></pre><p>索引:可以使用Python的索引方式</p><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])print(x)print(x[<span class="hljs-number">1</span>][<span class="hljs-number">2</span>])print(x[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])x[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>] = <span class="hljs-number">8</span>print(x)</code></pre><pre><code>tensor([[1, 2, 3],        [4, 5, 6]])tensor(6)tensor(6)tensor([[1, 8, 3],        [4, 5, 6]])</code></pre><p>使用<code>torch.Tensor.item()</code>返回张量的值</p><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">1</span>]])print(x)print(x.item())x = torch.tensor(<span class="hljs-number">2.5</span>)print(x)print(x.item())</code></pre><pre><code>tensor([[1]])1tensor(2.5000)2.5</code></pre><p>使用<code>requires_grad=True</code>让tensor张量能够记下操作记录,以致于可以求导</p><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">-1.</span>], [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]], requires_grad=<span class="hljs-literal">True</span>)out = x.pow(<span class="hljs-number">2</span>).sum() <span class="hljs-comment"># out = x^2</span>out.backward() <span class="hljs-comment"># 求导:out = 2 * x</span>print(x.grad)</code></pre><pre><code>tensor([[ 2., -2.],        [ 2.,  2.]])</code></pre><p>NOTE:当需要改变现存的tensor的device时,使用<code>to()</code>方法</p><h1 id="CLASS-torch-Tensor"><a href="#CLASS-torch-Tensor" class="headerlink" title="CLASS torch.Tensor"></a>CLASS torch.Tensor</h1><p>有几种创建tensor的方式</p><ol><li>用上述的<code>torch.tensor()</code>创建</li><li>用torch.*来创建指定size的张量</li><li>用一个张量的size来创建不同类型的张量,使用torch.*_like</li><li>用一个张量的类型创建不同size的张量,使用torch.new_*</li></ol><p>例如:<code>torch.rand(),torch.rand_like(),torch.randn(),torch.randn_like()</code><br><code>,torch.randint(),torch.randint_like(),torch.randperm(),torch.empty() </code></p><h2 id="new-tensor-data"><a href="#new-tensor-data" class="headerlink" title="new_tensor(data)"></a>new_tensor(data)</h2><p>创建一个数据为data其他都为原tensor类型的一个张量</p><pre><code class="hljs python">t = torch.ones((<span class="hljs-number">2</span>, ), dtype=torch.int8)data = [[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]]t.new_tensor(data)</code></pre><pre><code>tensor([[0, 1],        [2, 3]], dtype=torch.int8)</code></pre><h2 id="new-full-size-fill-value"><a href="#new-full-size-fill-value" class="headerlink" title="new_full(size, fill_value)"></a>new_full(size, fill_value)</h2><p>返回一个用fill_value填充的size维度的Tensor,默认返回的dtype和device相同<br>fill_value标量</p><pre><code class="hljs python">t = torch.ones((<span class="hljs-number">2</span>, ), dtype=torch.float64)t.new_full((<span class="hljs-number">3</span>, <span class="hljs-number">4</span>), <span class="hljs-number">3.141592</span>)</code></pre><pre><code>tensor([[3.1416, 3.1416, 3.1416, 3.1416],        [3.1416, 3.1416, 3.1416, 3.1416],        [3.1416, 3.1416, 3.1416, 3.1416]], dtype=torch.float64)</code></pre><h2 id="new-empty-size"><a href="#new-empty-size" class="headerlink" title="new_empty(size)"></a>new_empty(size)</h2><p>返回size维度的用随机初始化数据填充的Tensor</p><pre><code class="hljs python">t = torch.ones((<span class="hljs-number">1</span> ))print(t)t.new_empty((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))</code></pre><pre><code>tensor([1.])tensor([[0.0000e+00, 0.0000e+00, 1.4013e-45],        [0.0000e+00, 1.4013e-45, 0.0000e+00]])</code></pre><h2 id="new-ones-size"><a href="#new-ones-size" class="headerlink" title="new_ones(size)"></a>new_ones(size)</h2><p>返回一个size维度但是用1填充的Tensor</p><pre><code class="hljs python">t = torch.tensor((<span class="hljs-number">2.</span>))<span class="hljs-comment">#, dtype=torch.int32)</span>print(t.dtype)print(t.new_ones((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)))print(t)</code></pre><pre><code>torch.float32tensor([[1., 1., 1.],        [1., 1., 1.]])tensor(2.)</code></pre><h2 id="new-zeros-size"><a href="#new-zeros-size" class="headerlink" title="new_zeros(size)"></a>new_zeros(size)</h2><p>返回一个size大小用0填充的Tensor</p><pre><code class="hljs python">tensor = torch.tensor((), dtype=torch.float64)tensor.new_zeros((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))</code></pre><pre><code>tensor([[0., 0., 0.],        [0., 0., 0.]], dtype=torch.float64)</code></pre><h2 id="is-cuda"><a href="#is-cuda" class="headerlink" title="is_cuda()"></a>is_cuda()</h2><p>如果tensor存储在GPU中返回True,否则返回False</p><h2 id="is-quantized"><a href="#is-quantized" class="headerlink" title="is_quantized()"></a>is_quantized()</h2><p>如果tensor是量化的返回True,否则返回False</p><h2 id="device"><a href="#device" class="headerlink" title="device"></a>device</h2><p>返回Tensor存在哪</p><h2 id="grad"><a href="#grad" class="headerlink" title="grad"></a>grad</h2><p>记录求导<code>backward()</code>之后变量的值</p><h2 id="ndim"><a href="#ndim" class="headerlink" title="ndim"></a>ndim</h2><p>dim()的别名,返回的tensor的维度</p><h2 id="T"><a href="#T" class="headerlink" title="T"></a>T</h2><p>返回矩阵的转置</p><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]])print(x)print(x.T)</code></pre><pre><code>tensor([[0, 1],        [2, 3]])tensor([[0, 2],        [1, 3]])</code></pre><h2 id="abs-abs"><a href="#abs-abs" class="headerlink" title="abs() / abs_()"></a>abs() / abs_()</h2><p>与torch.abs()相同,返回矩阵中元素的绝对值</p><pre><code class="hljs python">torch.tensor([<span class="hljs-number">-1</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">3</span>]).abs()</code></pre><pre><code>tensor([1, 2, 3])</code></pre><h2 id="acos-acos"><a href="#acos-acos" class="headerlink" title="acos() / acos_()"></a>acos() / acos_()</h2><p>与torch.acos()相同,返回arccos反余弦值</p><h2 id="add-other-alpha-1-add"><a href="#add-other-alpha-1-add" class="headerlink" title="add(other, *, alpha=1) / add_()"></a>add(other, *, alpha=1) / add_()</h2><p>与torch.add()相同,返回张量+alpha*other</p><pre><code class="hljs python">x = torch.ones((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))print(x)x.add(<span class="hljs-number">1</span>, alpha=<span class="hljs-number">2</span>)</code></pre><pre><code>tensor([[1., 1., 1.],        [1., 1., 1.]])tensor([[3., 3., 3.],        [3., 3., 3.]])</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CNN_Dective_kdd99</title>
    <link href="/2020/03/24/CNN-Dective-kdd99/"/>
    <url>/2020/03/24/CNN-Dective-kdd99/</url>
    
    <content type="html"><![CDATA[<h1 id="PyTorch编程时遇到的问题"><a href="#PyTorch编程时遇到的问题" class="headerlink" title="PyTorch编程时遇到的问题"></a>PyTorch编程时遇到的问题</h1><a id="more"></a><h2 id="num-workers-0"><a href="#num-workers-0" class="headerlink" title="num_workers=0"></a>num_workers=0</h2><p>在windows中使用PyTorch中的dataloader中num_workers大于0或1就会提示：BrokenPipeError错误，这种是因为PyTorch调用了multiprocessing库。<a href="https://discuss.pytorch.org/t/%E3%80%81brokenpipeerror-errno-32-broken-pipe-when-i-run-cifar10-tutorial-py/6224/3">参考</a><br>解决方法：</p><ol><li>将num_workers设置为0或1，也就是不使用多进程</li><li>添加<code>if __name__ == &#39;__main__&#39;:</code>这条语句,windows必须要检测<strong>main</strong>(),否则就会出现错误，参考<a href="https://stackoverflow.com/questions/18204782/runtimeerror-on-windows-trying-python-multiprocessing">错误</a>，但是在jupyter notebook中使用了这条语句，依旧不管用。<h2 id="张量类型需要统一"><a href="#张量类型需要统一" class="headerlink" title="张量类型需要统一"></a>张量类型需要统一</h2>我们在定义张量时，首先dtype设置为普通类型例如：torch.float32,torch.int64,而不是将其设置为CPU tensor或者GPU tensor，并且网络中的参数也需要将其放入当GPU中(如果使用GPU运算的话)。可以使用这条语句net = net.to(device)<h2 id="注意卷积操作的维度"><a href="#注意卷积操作的维度" class="headerlink" title="注意卷积操作的维度"></a>注意卷积操作的维度</h2>在对CNN网络进行训练时，输入数据为维度为(N, C_in, H, W)输入维度为(N, C_out, H_out, W_out)，如果维度对应不上可以使用unsqueeze和squeeze函数对张量进行增维和降维。<h2 id="还有一个问题"><a href="#还有一个问题" class="headerlink" title="还有一个问题"></a>还有一个问题</h2>这个问题比较玄学，我刚开始几次训练时，CNN的识别率一直不动，保持相同的水平，但是在我们测试所有参数类型是否有问题后，并且运行的代码跟之前相比并没有改变什么变量，但是奇怪的时，识别率不仅大幅提高了，而且随着nepochs次数的增加，识别率也在提高，并且每次训练的时间都减少了。</li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这次很多编程上的问题，都没有注意，还得加强编程的训练，并且加强Linux的学习，毕竟在windows中不能使用多进程加载速度是真滴慢。</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>PyTorch</tag>
      
      <tag>入侵检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;&lt;基于特征分组聚类的异常入侵检测系统研究&gt;&gt;代码复现</title>
    <link href="/2019/12/02/kdd99/"/>
    <url>/2019/12/02/kdd99/</url>
    
    <content type="html"><![CDATA[<h1 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h1><a id="more"></a><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeanscolumns_names = [<span class="hljs-string">&#x27;duration&#x27;</span>, <span class="hljs-string">&#x27;protocol_type&#x27;</span>, <span class="hljs-string">&#x27;service&#x27;</span>, <span class="hljs-string">&#x27;flag&#x27;</span>, <span class="hljs-string">&#x27;src_bytes&#x27;</span>, <span class="hljs-string">&#x27;dst_bytes&#x27;</span>, <span class="hljs-string">&#x27;land&#x27;</span>, <span class="hljs-string">&#x27;wrong_fragment&#x27;</span>, <span class="hljs-string">&#x27;urgent&#x27;</span>, <span class="hljs-string">&#x27;hot&#x27;</span>, <span class="hljs-string">&#x27;num_failed_logins&#x27;</span>, <span class="hljs-string">&#x27;logged_in&#x27;</span>, <span class="hljs-string">&#x27;num_compromised&#x27;</span>, <span class="hljs-string">&#x27;root_shell&#x27;</span>, <span class="hljs-string">&#x27;su_attempted&#x27;</span>, <span class="hljs-string">&#x27;num_root&#x27;</span>, <span class="hljs-string">&#x27;num_file_creations&#x27;</span>, <span class="hljs-string">&#x27;num_shells&#x27;</span>, <span class="hljs-string">&#x27;num_access_files&#x27;</span>, <span class="hljs-string">&#x27;num_outbound_cmds&#x27;</span>, <span class="hljs-string">&#x27;is_host_login&#x27;</span>, <span class="hljs-string">&#x27;is_guest_login&#x27;</span>, <span class="hljs-string">&#x27;count&#x27;</span>, <span class="hljs-string">&#x27;srv_count&#x27;</span>, <span class="hljs-string">&#x27;serror_rate&#x27;</span>, <span class="hljs-string">&#x27;srv_serror_rate&#x27;</span>, <span class="hljs-string">&#x27;rerror_rate&#x27;</span>, <span class="hljs-string">&#x27;srv_rerror_rate&#x27;</span>, <span class="hljs-string">&#x27;same_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;diff_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;srv_diff_host_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_count&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_count&#x27;</span>, <span class="hljs-string">&#x27;dst_host_same_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_diff_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_same_src_port_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_diff_host_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_serror_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_serror_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_rerror_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_rerror_rate&#x27;</span>,<span class="hljs-string">&#x27;result&#x27;</span>]df = pd.read_csv(<span class="hljs-string">&#x27;./Sets/kddcup.data_10_percent/kddcup_10_percent.csv&#x27;</span>, names=columns_names)<span class="hljs-comment">#print(df.iloc[:,0:4])</span>kdd_data = df.iloc[:,:<span class="hljs-number">-1</span>]   <span class="hljs-comment"># 保存无标签数据集</span>kdd_target = df.iloc[:,<span class="hljs-number">-1</span>] <span class="hljs-comment"># 保存标签列</span></code></pre><p>输出部分数据，查看是否有误</p><pre><code class="hljs python">print(kdd_data.head())print(kdd_target.head())</code></pre><pre><code>   duration protocol_type service flag  src_bytes  dst_bytes  land  \0         0           tcp    http   SF        181       5450     0   1         0           tcp    http   SF        239        486     0   2         0           tcp    http   SF        235       1337     0   3         0           tcp    http   SF        219       1337     0   4         0           tcp    http   SF        217       2032     0      wrong_fragment  urgent  hot  ...  dst_host_count  dst_host_srv_count  \0               0       0    0  ...               9                   9   1               0       0    0  ...              19                  19   2               0       0    0  ...              29                  29   3               0       0    0  ...              39                  39   4               0       0    0  ...              49                  49      dst_host_same_srv_rate  dst_host_diff_srv_rate  \0                     1.0                     0.0   1                     1.0                     0.0   2                     1.0                     0.0   3                     1.0                     0.0   4                     1.0                     0.0      dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \0                         0.11                          0.0   1                         0.05                          0.0   2                         0.03                          0.0   3                         0.03                          0.0   4                         0.02                          0.0      dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \0                   0.0                       0.0                   0.0   1                   0.0                       0.0                   0.0   2                   0.0                       0.0                   0.0   3                   0.0                       0.0                   0.0   4                   0.0                       0.0                   0.0      dst_host_srv_rerror_rate  0                       0.0  1                       0.0  2                       0.0  3                       0.0  4                       0.0  [5 rows x 41 columns]0    normal.1    normal.2    normal.3    normal.4    normal.Name: result, dtype: object</code></pre><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>1.将类型为：string的列用one-hot编码数值化<br>2.将编码后的数据，再合并到原来的数据中，并且删除原本数据类型为string的列的数据<br>3.再使用最大最小化归一化</p><h2 id="ont-hot编码"><a href="#ont-hot编码" class="headerlink" title="ont-hot编码"></a>ont-hot编码</h2><pre><code class="hljs python">data = pd.get_dummies(df[[<span class="hljs-string">&#x27;protocol_type&#x27;</span>, <span class="hljs-string">&#x27;service&#x27;</span>, <span class="hljs-string">&#x27;flag&#x27;</span>]])print(len(data.columns))print(len(df.columns))</code></pre><pre><code>8042</code></pre><h2 id="合并数值化后的数据，删除原来string类型的数据"><a href="#合并数值化后的数据，删除原来string类型的数据" class="headerlink" title="合并数值化后的数据，删除原来string类型的数据"></a>合并数值化后的数据，删除原来string类型的数据</h2><pre><code class="hljs python">kdd_data_comb = pd.merge(kdd_data, data, how=<span class="hljs-string">&#x27;outer&#x27;</span>, left_index=<span class="hljs-literal">True</span>, right_index=<span class="hljs-literal">True</span>)print(kdd_data_comb.shape)<span class="hljs-comment"># print(list(kdd_data_comb.columns))</span><span class="hljs-comment"># print(list(kdd_data.columns))</span><span class="hljs-comment"># print(kdd_data.head())</span>kdd_data_comb = kdd_data_comb.drop(columns=[<span class="hljs-string">&#x27;protocol_type&#x27;</span>, <span class="hljs-string">&#x27;service&#x27;</span>, <span class="hljs-string">&#x27;flag&#x27;</span>])</code></pre><pre><code>(494021, 121)</code></pre><h2 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h2><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScalerscale = MinMaxScaler().fit(kdd_data_comb)kdd_dataScale = scale.transform(kdd_data_comb)</code></pre><h1 id="KMeans降维"><a href="#KMeans降维" class="headerlink" title="KMeans降维"></a>KMeans降维</h1><p>这里将数据按照论文中的方式，将数据集划分为4组，然后对每一组作Kmeans聚类</p><pre><code class="hljs python">model1 = KMeans(n_clusters=<span class="hljs-number">10</span>).fit(kdd_data_comb.loc[:,[<span class="hljs-string">&#x27;duration&#x27;</span>, <span class="hljs-string">&#x27;protocol_type_icmp&#x27;</span>, <span class="hljs-string">&#x27;protocol_type_tcp&#x27;</span>, <span class="hljs-string">&#x27;protocol_type_udp&#x27;</span>, <span class="hljs-string">&#x27;service_IRC&#x27;</span>, <span class="hljs-string">&#x27;service_X11&#x27;</span>, <span class="hljs-string">&#x27;service_Z39_50&#x27;</span>, <span class="hljs-string">&#x27;service_auth&#x27;</span>, <span class="hljs-string">&#x27;service_bgp&#x27;</span>, <span class="hljs-string">&#x27;service_courier&#x27;</span>, <span class="hljs-string">&#x27;service_csnet_ns&#x27;</span>, <span class="hljs-string">&#x27;service_ctf&#x27;</span>, <span class="hljs-string">&#x27;service_daytime&#x27;</span>, <span class="hljs-string">&#x27;service_discard&#x27;</span>, <span class="hljs-string">&#x27;service_domain&#x27;</span>, <span class="hljs-string">&#x27;service_domain_u&#x27;</span>, <span class="hljs-string">&#x27;service_echo&#x27;</span>, <span class="hljs-string">&#x27;service_eco_i&#x27;</span>, <span class="hljs-string">&#x27;service_ecr_i&#x27;</span>, <span class="hljs-string">&#x27;service_efs&#x27;</span>, <span class="hljs-string">&#x27;service_exec&#x27;</span>, <span class="hljs-string">&#x27;service_finger&#x27;</span>, <span class="hljs-string">&#x27;service_ftp&#x27;</span>, <span class="hljs-string">&#x27;service_ftp_data&#x27;</span>, <span class="hljs-string">&#x27;service_gopher&#x27;</span>, <span class="hljs-string">&#x27;service_hostnames&#x27;</span>, <span class="hljs-string">&#x27;service_http&#x27;</span>, <span class="hljs-string">&#x27;service_http_443&#x27;</span>, <span class="hljs-string">&#x27;service_imap4&#x27;</span>, <span class="hljs-string">&#x27;service_iso_tsap&#x27;</span>, <span class="hljs-string">&#x27;service_klogin&#x27;</span>, <span class="hljs-string">&#x27;service_kshell&#x27;</span>, <span class="hljs-string">&#x27;service_ldap&#x27;</span>, <span class="hljs-string">&#x27;service_link&#x27;</span>, <span class="hljs-string">&#x27;service_login&#x27;</span>, <span class="hljs-string">&#x27;service_mtp&#x27;</span>, <span class="hljs-string">&#x27;service_name&#x27;</span>, <span class="hljs-string">&#x27;service_netbios_dgm&#x27;</span>, <span class="hljs-string">&#x27;service_netbios_ns&#x27;</span>, <span class="hljs-string">&#x27;service_netbios_ssn&#x27;</span>, <span class="hljs-string">&#x27;service_netstat&#x27;</span>, <span class="hljs-string">&#x27;service_nnsp&#x27;</span>, <span class="hljs-string">&#x27;service_nntp&#x27;</span>, <span class="hljs-string">&#x27;service_ntp_u&#x27;</span>, <span class="hljs-string">&#x27;service_other&#x27;</span>, <span class="hljs-string">&#x27;service_pm_dump&#x27;</span>, <span class="hljs-string">&#x27;service_pop_2&#x27;</span>, <span class="hljs-string">&#x27;service_pop_3&#x27;</span>, <span class="hljs-string">&#x27;service_printer&#x27;</span>, <span class="hljs-string">&#x27;service_private&#x27;</span>, <span class="hljs-string">&#x27;service_red_i&#x27;</span>, <span class="hljs-string">&#x27;service_remote_job&#x27;</span>, <span class="hljs-string">&#x27;service_rje&#x27;</span>, <span class="hljs-string">&#x27;service_shell&#x27;</span>, <span class="hljs-string">&#x27;service_smtp&#x27;</span>, <span class="hljs-string">&#x27;service_sql_net&#x27;</span>, <span class="hljs-string">&#x27;service_ssh&#x27;</span>, <span class="hljs-string">&#x27;service_sunrpc&#x27;</span>, <span class="hljs-string">&#x27;service_supdup&#x27;</span>, <span class="hljs-string">&#x27;service_systat&#x27;</span>, <span class="hljs-string">&#x27;service_telnet&#x27;</span>, <span class="hljs-string">&#x27;service_tftp_u&#x27;</span>, <span class="hljs-string">&#x27;service_tim_i&#x27;</span>, <span class="hljs-string">&#x27;service_time&#x27;</span>, <span class="hljs-string">&#x27;service_urh_i&#x27;</span>, <span class="hljs-string">&#x27;service_urp_i&#x27;</span>, <span class="hljs-string">&#x27;service_uucp&#x27;</span>, <span class="hljs-string">&#x27;service_uucp_path&#x27;</span>, <span class="hljs-string">&#x27;service_vmnet&#x27;</span>, <span class="hljs-string">&#x27;service_whois&#x27;</span>, <span class="hljs-string">&#x27;flag_OTH&#x27;</span>, <span class="hljs-string">&#x27;flag_REJ&#x27;</span>, <span class="hljs-string">&#x27;flag_RSTO&#x27;</span>, <span class="hljs-string">&#x27;flag_RSTOS0&#x27;</span>, <span class="hljs-string">&#x27;flag_RSTR&#x27;</span>, <span class="hljs-string">&#x27;flag_S0&#x27;</span>, <span class="hljs-string">&#x27;flag_S1&#x27;</span>, <span class="hljs-string">&#x27;flag_S2&#x27;</span>, <span class="hljs-string">&#x27;flag_S3&#x27;</span>, <span class="hljs-string">&#x27;flag_SF&#x27;</span>, <span class="hljs-string">&#x27;flag_SH&#x27;</span>, <span class="hljs-string">&#x27;src_bytes&#x27;</span>, <span class="hljs-string">&#x27;dst_bytes&#x27;</span>, <span class="hljs-string">&#x27;land&#x27;</span>, <span class="hljs-string">&#x27;wrong_fragment&#x27;</span>, <span class="hljs-string">&#x27;urgent&#x27;</span>]])model2 = KMeans(n_clusters=<span class="hljs-number">10</span>).fit(kdd_data_comb.loc[:,[<span class="hljs-string">&#x27;hot&#x27;</span>, <span class="hljs-string">&#x27;num_failed_logins&#x27;</span>, <span class="hljs-string">&#x27;logged_in&#x27;</span>, <span class="hljs-string">&#x27;num_compromised&#x27;</span>, <span class="hljs-string">&#x27;root_shell&#x27;</span>, <span class="hljs-string">&#x27;su_attempted&#x27;</span>, <span class="hljs-string">&#x27;num_root&#x27;</span>, <span class="hljs-string">&#x27;num_file_creations&#x27;</span>, <span class="hljs-string">&#x27;num_shells&#x27;</span>, <span class="hljs-string">&#x27;num_access_files&#x27;</span>, <span class="hljs-string">&#x27;num_outbound_cmds&#x27;</span>, <span class="hljs-string">&#x27;is_host_login&#x27;</span>, <span class="hljs-string">&#x27;is_guest_login&#x27;</span>]])model3 = KMeans(n_clusters=<span class="hljs-number">10</span>).fit(kdd_data_comb.loc[:,[<span class="hljs-string">&#x27;count&#x27;</span>, <span class="hljs-string">&#x27;srv_count&#x27;</span>, <span class="hljs-string">&#x27;serror_rate&#x27;</span>, <span class="hljs-string">&#x27;srv_serror_rate&#x27;</span>, <span class="hljs-string">&#x27;rerror_rate&#x27;</span>, <span class="hljs-string">&#x27;srv_rerror_rate&#x27;</span>, <span class="hljs-string">&#x27;same_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;diff_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;srv_diff_host_rate&#x27;</span>]])model4 = KMeans(n_clusters=<span class="hljs-number">10</span>).fit(kdd_data_comb.loc[:,[<span class="hljs-string">&#x27;dst_host_count&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_count&#x27;</span>, <span class="hljs-string">&#x27;dst_host_same_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_diff_srv_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_same_src_port_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_diff_host_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_serror_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_serror_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_rerror_rate&#x27;</span>, <span class="hljs-string">&#x27;dst_host_srv_rerror_rate&#x27;</span>]])</code></pre><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> npnp.unique(model1.labels_) <span class="hljs-comment"># 这里显示聚类结果中所有的值，如果只是打印出来，看不到除0以外的其他值</span></code></pre><pre><code>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre><pre><code class="hljs python">sizes = [(model1.labels_ == i).sum() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>) ] <span class="hljs-comment">#每块值</span>print(sizes)print(len(model1.labels_))</code></pre><pre><code>[491472, 1, 59, 16, 24, 21, 6, 77, 2343, 2]494021</code></pre><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> pltplt.figure(figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">9</span>)) <span class="hljs-comment">#调节图形大小</span>labels = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>] <span class="hljs-comment">#定义标签</span><span class="hljs-comment"># sizes = [i for i in range(10): model1.labels_ == i] #每块值</span>explode = (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>) <span class="hljs-comment">#将某一块分割出来，值越大分割出的间隙越大</span>patches,text1,text2 = plt.pie(sizes,                      explode=explode,                      labels=labels,                      autopct = <span class="hljs-string">&#x27;%3.2f%%&#x27;</span>, <span class="hljs-comment">#数值保留固定小数位</span>                      shadow = <span class="hljs-literal">False</span>, <span class="hljs-comment">#无阴影设置</span>                      startangle =<span class="hljs-number">90</span>, <span class="hljs-comment">#逆时针起始角度设置</span>                      pctdistance = <span class="hljs-number">0.6</span>) <span class="hljs-comment">#数值距圆心半径倍数距离</span><span class="hljs-comment">#patches饼图的返回值，texts1饼图外label的文本，texts2饼图内部的文本</span><span class="hljs-comment"># x，y轴刻度设置一致，保证饼图为圆形</span>plt.axis(<span class="hljs-string">&#x27;equal&#x27;</span>)plt.show()</code></pre><pre><code>&lt;Figure size 600x900 with 1 Axes&gt;</code></pre><h2 id="合并降维后的数据"><a href="#合并降维后的数据" class="headerlink" title="合并降维后的数据"></a>合并降维后的数据</h2><p>可以看到数据经过kmeans降维后，数据集就变成了只有4维的数据了</p><pre><code class="hljs python">data_kmeansed = pd.DataFrame(&#123;<span class="hljs-string">&#x27;model1&#x27;</span>: model1.labels_, <span class="hljs-string">&#x27;model2&#x27;</span>: model2.labels_, <span class="hljs-string">&#x27;model3&#x27;</span>: model3.labels_, <span class="hljs-string">&#x27;model4&#x27;</span>: model4.labels_&#125;, columns=[<span class="hljs-string">&#x27;model1&#x27;</span>, <span class="hljs-string">&#x27;model2&#x27;</span>, <span class="hljs-string">&#x27;model3&#x27;</span>, <span class="hljs-string">&#x27;model4&#x27;</span>])print(data_kmeansed.head())print(data_kmeansed.shape)</code></pre><pre><code>   model1  model2  model3  model40       0       4       2       31       0       4       2       32       0       4       2       33       0       4       2       34       0       4       2       3(494021, 4)</code></pre><pre><code class="hljs python"><span class="hljs-comment"># data_kmeansed_onehot = pd.get_dummies(data_kmeansed[[&#x27;model1&#x27;, &#x27;model2&#x27;, &#x27;model3&#x27;, &#x27;model4&#x27;]])</span><span class="hljs-comment"># print(pd.get_dummies(data_kmeansed[[&#x27;model1&#x27;, &#x27;model2&#x27;, &#x27;model3&#x27;, &#x27;model4&#x27;]]).head()) # 可以看到这里对数据值数据进行one-hot编码数值不变</span></code></pre><h2 id="标签处理"><a href="#标签处理" class="headerlink" title="标签处理"></a>标签处理</h2><p>该模型只对5种大类型的攻击方式进行预测，但是数据集中原标签全是小类型，需要将小类型的标签，根据攻击方式的不同划分到大类型中</p><pre><code class="hljs python">np.unique(kdd_target) <span class="hljs-comment"># 显示当前标签中的值</span></code></pre><pre><code>array([&#39;back.&#39;, &#39;buffer_overflow.&#39;, &#39;ftp_write.&#39;, &#39;guess_passwd.&#39;,       &#39;imap.&#39;, &#39;ipsweep.&#39;, &#39;land.&#39;, &#39;loadmodule.&#39;, &#39;multihop.&#39;,       &#39;neptune.&#39;, &#39;nmap.&#39;, &#39;normal.&#39;, &#39;perl.&#39;, &#39;phf.&#39;, &#39;pod.&#39;,       &#39;portsweep.&#39;, &#39;rootkit.&#39;, &#39;satan.&#39;, &#39;smurf.&#39;, &#39;spy.&#39;, &#39;teardrop.&#39;,       &#39;warezclient.&#39;, &#39;warezmaster.&#39;], dtype=object)</code></pre><pre><code class="hljs python">kdd_target_test = kdd_target.copy(<span class="hljs-literal">True</span>) <span class="hljs-comment"># 深度复制</span></code></pre><pre><code class="hljs python"><span class="hljs-comment"># 做个映射将标签中的小类，按照先验知识划分为5个大类</span></code></pre><pre><code class="hljs python"><span class="hljs-comment"># print(kdd_target_test[kdd_target_test==&#x27;Dos&#x27;].head())</span>print(np.unique(kdd_target))</code></pre><pre><code>[&#39;Dos&#39; &#39;R2L&#39; &#39;U2R&#39; &#39;normal&#39; &#39;probe&#39;]</code></pre><p>替换</p><pre><code class="hljs python">Dos_target = &#123;<span class="hljs-string">&#x27;back.&#x27;</span>:<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;neptune.&#x27;</span>:<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;pod.&#x27;</span>:<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;smurf.&#x27;</span>:<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;land.&#x27;</span>:<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;teardrop.&#x27;</span>:<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;normal.&#x27;</span>:<span class="hljs-string">&#x27;normal&#x27;</span>,<span class="hljs-string">&#x27;ipsweep.&#x27;</span>:<span class="hljs-string">&#x27;probe&#x27;</span>, <span class="hljs-string">&#x27;nmap.&#x27;</span>:<span class="hljs-string">&#x27;probe&#x27;</span>, <span class="hljs-string">&#x27;portsweep.&#x27;</span>:<span class="hljs-string">&#x27;probe&#x27;</span>, <span class="hljs-string">&#x27;satan.&#x27;</span>:<span class="hljs-string">&#x27;probe&#x27;</span>, <span class="hljs-string">&#x27;ftp_write.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;guess_passwd.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;imap.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;multihop.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;phf.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;spy.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;warezclient.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;warezmaster.&#x27;</span>:<span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;buffer_overflow.&#x27;</span>:<span class="hljs-string">&#x27;U2R&#x27;</span>, <span class="hljs-string">&#x27;loadmodule.&#x27;</span>:<span class="hljs-string">&#x27;U2R&#x27;</span>, <span class="hljs-string">&#x27;perl.&#x27;</span>:<span class="hljs-string">&#x27;U2R&#x27;</span>, <span class="hljs-string">&#x27;rootkit.&#x27;</span>:<span class="hljs-string">&#x27;U2R&#x27;</span>&#125;kdd_target = kdd_target_test.map(Dos_target)</code></pre><h1 id="决策树做训练"><a href="#决策树做训练" class="headerlink" title="决策树做训练"></a>决策树做训练</h1><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> treetree_model = tree.DecisionTreeClassifier(criterion=<span class="hljs-string">&#x27;entropy&#x27;</span>,random_state=<span class="hljs-number">30</span>)<span class="hljs-comment"># criterion=&#x27;entropy&#x27;调用的就是C4.5算法，默认是CART</span>tree_model.fit(data_kmeansed, kdd_target)</code></pre><pre><code>DecisionTreeClassifier(class_weight=None, criterion=&#39;entropy&#39;, max_depth=None,                       max_features=None, max_leaf_nodes=None,                       min_impurity_decrease=0.0, min_impurity_split=None,                       min_samples_leaf=1, min_samples_split=2,                       min_weight_fraction_leaf=0.0, presort=False,                       random_state=30, splitter=&#39;best&#39;)</code></pre><pre><code class="hljs python"><span class="hljs-comment"># data_kmeansed.isnull().sum()</span></code></pre><pre><code>model1    0model2    0model3    0model4    0dtype: int64</code></pre><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_scorenormal_data = data_kmeansed[kdd_target == <span class="hljs-string">&#x27;normal&#x27;</span>]print(normal_data.shape)</code></pre><pre><code>(97278, 4)</code></pre><pre><code class="hljs python">back_predict = tree_model.predict(normal_data)</code></pre><p>计算各个类的预测成功率</p><pre><code class="hljs python">y_data = []target = [<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;probe&#x27;</span>, <span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;U2R&#x27;</span>,<span class="hljs-string">&#x27;normal&#x27;</span>]<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> target:    data1 = data_kmeansed[kdd_target == i]    back_predict = tree_model.predict(data1)    y_data.append(accuracy_score(kdd_target[kdd_target == i], back_predict))</code></pre><pre><code class="hljs python">y_data</code></pre><pre><code>[0.9955167604187423, 0.4390065741417093, 0.325044404973357, 0.038461538461538464, 0.9968852155677542]</code></pre><p>各个类的检测率的可视化</p><pre><code class="hljs python">x_data = [<span class="hljs-string">&#x27;Dos&#x27;</span>, <span class="hljs-string">&#x27;probe&#x27;</span>, <span class="hljs-string">&#x27;R2L&#x27;</span>, <span class="hljs-string">&#x27;U2R&#x27;</span>, <span class="hljs-string">&#x27;normal&#x27;</span>]bar_width = <span class="hljs-number">0.3</span>plt.bar(x=x_data, height=y_data, label=<span class="hljs-string">&#x27;检测正确率&#x27;</span>, color=<span class="hljs-string">&#x27;steelblue&#x27;</span>, alpha=<span class="hljs-number">0.8</span>, width=bar_width)plt.xticks(x_data)plt.show()</code></pre><p><img src="/images/output_35_0.png" alt="output_35_0"></p><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrixdata1 = data_kmeansedkdd_predict = tree_model.predict(data1)pd.DataFrame(    confusion_matrix(kdd_target, kdd_predict),     columns=[<span class="hljs-string">&#x27;预测Dos&#x27;</span>, <span class="hljs-string">&#x27;预测probe&#x27;</span>, <span class="hljs-string">&#x27;预测R2L&#x27;</span>, <span class="hljs-string">&#x27;预测U2R&#x27;</span>, <span class="hljs-string">&#x27;预测normal&#x27;</span>],    index=[<span class="hljs-string">&#x27;实际Dos&#x27;</span>, <span class="hljs-string">&#x27;实际probe&#x27;</span>, <span class="hljs-string">&#x27;实际R2L&#x27;</span>, <span class="hljs-string">&#x27;实际U2R&#x27;</span>,<span class="hljs-string">&#x27;实际normal&#x27;</span>])</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>预测Dos</th>      <th>预测probe</th>      <th>预测R2L</th>      <th>预测U2R</th>      <th>预测normal</th>    </tr>  </thead>  <tbody>    <tr>      <td>实际Dos</td>      <td>389703</td>      <td>0</td>      <td>0</td>      <td>1746</td>      <td>9</td>    </tr>    <tr>      <td>实际probe</td>      <td>0</td>      <td>366</td>      <td>0</td>      <td>760</td>      <td>0</td>    </tr>    <tr>      <td>实际R2L</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>50</td>      <td>0</td>    </tr>    <tr>      <td>实际U2R</td>      <td>225</td>      <td>28</td>      <td>0</td>      <td>96975</td>      <td>50</td>    </tr>    <tr>      <td>实际normal</td>      <td>264</td>      <td>0</td>      <td>0</td>      <td>2040</td>      <td>1803</td>    </tr>  </tbody></table></div><h1 id="计算F1的值"><a href="#计算F1的值" class="headerlink" title="计算F1的值"></a>计算F1的值</h1><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_scoreprint(f1_score(kdd_target, kdd_predict, average=<span class="hljs-literal">None</span>))</code></pre><pre><code>[0.99712915 0.48157895 0.07407407 0.97536322 0.60412129]</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>MachineLearning</tag>
      
      <tag>IDS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>通用ShellCode</title>
    <link href="/2019/06/25/%E9%80%9A%E7%94%A8shellcode/"/>
    <url>/2019/06/25/%E9%80%9A%E7%94%A8shellcode/</url>
    
    <content type="html"><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <div class="hbe-input-container">  <input type="password" id="hbePass" placeholder="" />    <label for="hbePass">Hey, password is required here.</label>    <div class="bottom-line"></div>  </div>  <script id="hbeData" type="hbeData" data-hmacdigest="8703da56f848118753210c175a4e7fb25b0bd8f81985036bb681065ef59fa705">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</script></div><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    
    
    <tags>
      
      <tag>shellcode</tag>
      
      <tag>二进制</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
